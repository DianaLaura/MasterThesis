{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 2: DTA, linear regression and selecting features that occur a certain amount of time**\n",
    "\n",
    "*Background*: Experiment 1 showed that some sort of feature selection is required, but also that just picking the k highest scoring features leads to overfitting.\n",
    "\n",
    "*Goal*: Determine if it is possible to predict the year in which a text was written using regression.\n",
    "\n",
    "*Strategies*:\n",
    "- Train on features that occur a certain amount of time\n",
    "\n",
    "*Relevance*:\n",
    "- If this experiment works, it is possible to estimate years for corpora that have NA's in this variable.\n",
    "\n",
    "*Success criteria*:\n",
    "- Consistent findings over training-, test- and validation set\n",
    "- predicted year is not more than ten years away from the true year\n",
    "\n",
    "*Corpora*:\n",
    "- DTA\n",
    "\n",
    "*Result*: \n",
    "Only using features that occur in 800 out of 899 documents solved the problem of overfitting.\n",
    "\n",
    "The linear regression seems to try to model a normal distribution, which does not reflect the real distribution of years in the DTA (cf analysis notebook). Therefore, it seems that linear regression is not flexible enough to model the data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest , f_regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.utils\n",
    "import re\n",
    "\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Starting R for statistical analysis\n",
    "from rpy2 import robjects\n",
    "\n",
    "from rpy2.robjects import pandas2ri\n",
    "from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "\n",
    "\n",
    "R = robjects.r\n",
    "\n",
    "ggplot = importr('ggplot2')\n",
    "\n",
    "tidyr = importr('tidyr')\n",
    "\n",
    "dplyr = importr('dplyr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code example: https://stackoverflow.com/questions/39839112/the-easiest-way-for-getting-feature-names-after-running-selectkbest-in-scikit-le\n",
    "def features_to_names(features, feature_names):\n",
    "    features_selected = []\n",
    "\n",
    "    for bool, feature in zip(features, feature_names):\n",
    "        if bool:\n",
    "            features_selected.append(feature)\n",
    "    return features_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('/Volumes/Korpora/Train/DTA_train_tokenized.csv', sep=';')\n",
    "val_full = pd.read_csv('/Volumes/Korpora/Val/DTA_val_tokenized.csv', sep=';')\n",
    "test_full = pd.read_csv('/Volumes/Korpora/Test/DTA_test_tokenized.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set:  899\n",
      "Length validation set:  225\n",
      "Length test set:  281\n"
     ]
    }
   ],
   "source": [
    "print('Length train set: ',len(train_full))\n",
    "print('Length validation set: ', len(val_full))\n",
    "print('Length test set: ', len(test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build tokenizer that just substitutes '[' and ']' with ','\n",
    "def tokenizer_word(doc):\n",
    "    doc = re.sub('[(\\[+)|(\\]+)]', '', doc)\n",
    "    doc = re.split(',', doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for assembling predictions in order to find out how features are weighted\n",
    "\n",
    "def collect_predictions(dataset, classifier,vectorizer, feature_names, pipeline):\n",
    "    predictions = eli5.explain_weights_df(classifier,vec=vectorizer, feature_names=feature_names)\n",
    "    \n",
    "    predictions = predictions.drop(['target'], axis=1)\n",
    "    \n",
    "    \n",
    "    predictions['YEAR'] = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    for instance in range (0, len(dataset)):\n",
    "        pred = eli5.explain_prediction_df(classifier, dataset[instance], vec=vectorizer, feature_names=feature_names)\n",
    "        source_text = pd.DataFrame([[dataset[instance]]])\n",
    "        year_pred = pipeline.predict(source_text[0])\n",
    "        pred['weight_value'] = pred['weight'] * pred['value']\n",
    "        pred['instance'] = instance\n",
    "        \n",
    "        \n",
    "        pred = pred.drop(['target','weight','value'], axis=1)\n",
    "        \n",
    "    \n",
    "        pred['YEAR'] = np.round(year_pred[0])\n",
    "    \n",
    "        predictions = pd.concat([predictions, pred])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_full['Text']\n",
    "train_y = train_full['Publication_year']\n",
    "\n",
    "val_x = val_full['Text']\n",
    "val_y = val_full['Publication_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CountVectorizer has an attribute called min_df that can be set to an integer or a float. If a word occurs less often than min_df (count or distribution), it is removed. I set min_df to 10 for the next experiment.\n",
    "\n",
    "In Experiment 1, the model performed best on a set with 22000 features, so I start with that value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_1 = Pipeline([ ('unigram_vectorizer', CountVectorizer(tokenizer=tokenizer_word, min_df = 10)),\n",
    "                    ('feature_selector', SelectKBest(f_regression, k=22000)),\n",
    "                         ('ridge_reg', linear_model.Ridge())\n",
    "                        ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = reg_1.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = reg_1.predict(val_x)\n",
    "\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reg_1['feature_selector'].get_support()\n",
    "feature_names = reg_1['unigram_vectorizer'].get_feature_names()\n",
    "\n",
    "features_selected = features_to_names(features, feature_names)\n",
    "\n",
    "expl = eli5.explain_weights_df(reg_1['ridge_reg'],vec=reg_1['unigram_vectorizer'],target_names=(train_y),feature_names=features_selected)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(expl.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is still overfitting heavily, so I raise the threshold to 100.\n",
    "\n",
    "Since there are less than 22k features over the threshold, I set k to 'all' for now, because else the feature selector does complain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_2 = Pipeline([ ('unigram_vectorizer', CountVectorizer(tokenizer=tokenizer_word, min_df = 100)),\n",
    "                    ('feature_selector', SelectKBest(f_regression, k='all')),\n",
    "                         ('ridge_reg', linear_model.Ridge())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = reg_2.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = reg_2.predict(val_x)\n",
    "\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reg_2['feature_selector'].get_support()\n",
    "feature_names = reg_2['unigram_vectorizer'].get_feature_names()\n",
    "\n",
    "features_selected = features_to_names(features, feature_names)\n",
    "\n",
    "eli5.show_weights(reg_2['ridge_reg'],vec=reg_2['unigram_vectorizer'], feature_names=features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_3 = Pipeline([ ('unigram_vectorizer', CountVectorizer(tokenizer=tokenizer_word, min_df = 200)),\n",
    "                    ('feature_selector', SelectKBest(f_regression, k='all')),\n",
    "                         ('ridge_reg', linear_model.Ridge())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_3.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = reg_3.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_val = reg_3.predict(val_x)\n",
    "\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = reg_3['feature_selector'].get_support()\n",
    "feature_names = reg_3['unigram_vectorizer'].get_feature_names()\n",
    "\n",
    "features_selected = features_to_names(features, feature_names)\n",
    "\n",
    "eli5.show_weights(reg_3['ridge_reg'],vec=reg_3['unigram_vectorizer'], feature_names=features_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the model is still overfitting, I reverse the experiment, and I just pick features that occur in 800 out of 899 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_4 = Pipeline([ ('unigram_vectorizer', CountVectorizer(tokenizer=tokenizer_word, min_df = 800)),\n",
    "                    ('feature_selector', SelectKBest(f_regression, k='all')),\n",
    "                         ('ridge_reg', linear_model.Ridge())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('unigram_vectorizer',\n",
       "                 CountVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.int64'>, encoding='utf-8',\n",
       "                                 input='content', lowercase=True, max_df=1.0,\n",
       "                                 max_features=None, min_df=800,\n",
       "                                 ngram_range=(1, 1), preprocessor=None,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<function tokenizer_word at 0x1ddc45c20>,\n",
       "                                 vocabulary=None)),\n",
       "                ('feature_selector',\n",
       "                 SelectKBest(k='all',\n",
       "                             score_func=<function f_regression at 0x125002cb0>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_4.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2259.798810884709"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_4.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3202.5089784523752"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_4.predict(val_x)\n",
    "\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "        \n",
       "            \n",
       "                \n",
       "                \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1769.725\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.282\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;keine&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.261\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;weiter&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.217\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;ja&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.181\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;that&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.178\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;leicht&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.176\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;vielen&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.155\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;finden&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.153\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;erhalten&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.152\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(120, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;liegen&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.97%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 110 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 86 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.159\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;jeden&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.165\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;welchen&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.166\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;alle&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.173\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;einander&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.176\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;genug&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.177\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;gen&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.97%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.180\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;bald&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.222\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;ins&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.96%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.230\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;weit&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.95%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.340\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        <span style=\"background-color: hsl(0, 80%, 70%); margin: 0 0.1em 0 0\" title=\"A space symbol\">&emsp;</span>&#x27;kein&#x27;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "            \n",
       "        \n",
       "\n",
       "        \n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "Explanation(estimator=\"Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\\n      normalize=False, random_state=None, solver='auto', tol=0.001)\", description=\"\\nFeatures with largest coefficients.\\nCaveats:\\n1. Be careful with features which are not\\n   independent - weights don't show their importance.\\n2. If scale of input features is different then scale of coefficients\\n   will also be different, making direct comparison between coefficient values\\n   incorrect.\\n3. Depending on regularization, rare features sometimes may have high\\n   coefficients; this doesn't mean they contribute much to the\\n   classification result for most examples.\\n\", error=None, method='linear model', is_regression=True, targets=[TargetExplanation(target='y', feature_weights=FeatureWeights(pos=[FeatureWeight(feature='<BIAS>', weight=1769.72498378178, std=None, value=None), FeatureWeight(feature=\" 'keine'\", weight=0.28215865189276, std=None, value=None), FeatureWeight(feature=\" 'weiter'\", weight=0.2605753331467955, std=None, value=None), FeatureWeight(feature=\" 'ja'\", weight=0.21697707009698006, std=None, value=None), FeatureWeight(feature=\" 'that'\", weight=0.18137675105525447, std=None, value=None), FeatureWeight(feature=\" 'leicht'\", weight=0.17787227899112906, std=None, value=None), FeatureWeight(feature=\" 'vielen'\", weight=0.17585700726028217, std=None, value=None), FeatureWeight(feature=\" 'finden'\", weight=0.15523597279447018, std=None, value=None), FeatureWeight(feature=\" 'erhalten'\", weight=0.1531355142374395, std=None, value=None), FeatureWeight(feature=\" 'liegen'\", weight=0.1520930530436624, std=None, value=None)], neg=[FeatureWeight(feature=\" 'kein'\", weight=-0.3395522074968795, std=None, value=None), FeatureWeight(feature=\" 'weit'\", weight=-0.22985734790484544, std=None, value=None), FeatureWeight(feature=\" 'ins'\", weight=-0.22189071325635346, std=None, value=None), FeatureWeight(feature=\" 'bald'\", weight=-0.1796849913742998, std=None, value=None), FeatureWeight(feature=\" 'gen'\", weight=-0.17659622069132203, std=None, value=None), FeatureWeight(feature=\" 'genug'\", weight=-0.17566194219113015, std=None, value=None), FeatureWeight(feature=\" 'einander'\", weight=-0.17344353728272038, std=None, value=None), FeatureWeight(feature=\" 'alle'\", weight=-0.16552632871642325, std=None, value=None), FeatureWeight(feature=\" 'welchen'\", weight=-0.1647060671157467, std=None, value=None), FeatureWeight(feature=\" 'jeden'\", weight=-0.15880460654825063, std=None, value=None)], pos_remaining=110, neg_remaining=86), proba=None, score=None, weighted_spans=None, heatmap=None)], feature_importances=None, decision_tree=None, highlight_spaces=None, transition_features=None, image=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = reg_4['feature_selector'].get_support()\n",
    "feature_names = reg_4['unigram_vectorizer'].get_feature_names()\n",
    "\n",
    "features_selected = features_to_names(features, feature_names)\n",
    "\n",
    "eli5.explain_weights(reg_4['ridge_reg'],vec=reg_4['unigram_vectorizer'], feature_names=features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MSE of the train and val set converged now, so going after the stop words seems to be a pretty good idea. The model trained on 215 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted_y  Publication_year  Difference\n",
      "0  1786.259536              1741   45.259536\n",
      "1  1750.030794              1691   59.030794\n",
      "2  1770.757624              1665  105.757624\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = pd.DataFrame(y_pred_train, columns=['Predicted_y'])\n",
    "\n",
    "diff_pred_true_train = pd.concat([y_pred_train, train_y], axis=1)\n",
    "\n",
    "diff_pred_true_train['Difference'] = diff_pred_true_train.Predicted_y - diff_pred_true_train.Publication_year\n",
    "    \n",
    "\n",
    "print(diff_pred_true_train.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_y</th>\n",
       "      <th>Publication_year</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>899.000000</td>\n",
       "      <td>899.000000</td>\n",
       "      <td>8.990000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1788.259177</td>\n",
       "      <td>1788.259177</td>\n",
       "      <td>-4.426073e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>61.741568</td>\n",
       "      <td>77.929074</td>\n",
       "      <td>4.756380e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1549.902463</td>\n",
       "      <td>1598.000000</td>\n",
       "      <td>-1.258733e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1762.839429</td>\n",
       "      <td>1739.500000</td>\n",
       "      <td>-2.805162e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1782.950146</td>\n",
       "      <td>1796.000000</td>\n",
       "      <td>2.362674e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1824.280243</td>\n",
       "      <td>1855.000000</td>\n",
       "      <td>2.514667e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1962.413722</td>\n",
       "      <td>1913.000000</td>\n",
       "      <td>1.671227e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted_y  Publication_year    Difference\n",
       "count   899.000000        899.000000  8.990000e+02\n",
       "mean   1788.259177       1788.259177 -4.426073e-14\n",
       "std      61.741568         77.929074  4.756380e+01\n",
       "min    1549.902463       1598.000000 -1.258733e+02\n",
       "25%    1762.839429       1739.500000 -2.805162e+01\n",
       "50%    1782.950146       1796.000000  2.362674e-02\n",
       "75%    1824.280243       1855.000000  2.514667e+01\n",
       "max    1962.413722       1913.000000  1.671227e+02"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_pred_true_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This table shows that the mean of the years is the same for the predicted and the true year. The maximum and minimum of the model's prediction is lower and higher than in the true labels, so the model thinks that the range between the earliest and the latest publication year is larger than shown in the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Predicted_y  Publication_year  Difference\n",
      "0  1818.768364              1897  -78.231636\n",
      "1  1717.750097              1701   16.750097\n",
      "2  1517.937050              1663 -145.062950\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = pd.DataFrame(y_pred_val, columns=['Predicted_y'])\n",
    "\n",
    "diff_pred_true_val = pd.concat([y_pred_val, val_y], axis=1)\n",
    "\n",
    "diff_pred_true_val['Difference'] = diff_pred_true_val.Predicted_y - diff_pred_true_val.Publication_year\n",
    "\n",
    "print(diff_pred_true_val.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted_y</th>\n",
       "      <th>Publication_year</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>225.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1789.651089</td>\n",
       "      <td>1791.315556</td>\n",
       "      <td>-1.664467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>70.223421</td>\n",
       "      <td>74.822785</td>\n",
       "      <td>56.692355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1482.561566</td>\n",
       "      <td>1603.000000</td>\n",
       "      <td>-164.438434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1763.628141</td>\n",
       "      <td>1750.000000</td>\n",
       "      <td>-35.216816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1784.658281</td>\n",
       "      <td>1804.000000</td>\n",
       "      <td>-5.313875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1822.392752</td>\n",
       "      <td>1843.000000</td>\n",
       "      <td>28.570888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2025.898784</td>\n",
       "      <td>1913.000000</td>\n",
       "      <td>255.349277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Predicted_y  Publication_year  Difference\n",
       "count   225.000000        225.000000  225.000000\n",
       "mean   1789.651089       1791.315556   -1.664467\n",
       "std      70.223421         74.822785   56.692355\n",
       "min    1482.561566       1603.000000 -164.438434\n",
       "25%    1763.628141       1750.000000  -35.216816\n",
       "50%    1784.658281       1804.000000   -5.313875\n",
       "75%    1822.392752       1843.000000   28.570888\n",
       "max    2025.898784       1913.000000  255.349277"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_pred_true_val.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The true mean of the publication year in the validation set is three years higher than in the train set. The model adapts slightly by adding one year to the mean of the predictions over the validation set (compared to the train set).\n",
    "\n",
    "Surprisingly, the model dates the oldest text from the validation set back to 1462, when in fact, the oldest text was written in 1603. The youngest text in the validation set, according to the model, was written in 2014, the true year of the youngest text is 1913. This means that the range of the prediction is about 350 years larger than it should be.\n",
    "\n",
    "The mean difference between the predicted and the true year is -2, meaning that the predicted year is generally two years lower than the true label.\n",
    "\n",
    "in the first quartile, the models prediction is about 37 years to low, in the third quartile, the prediction is about 256 years to high. It seems that the model generally tends to predict a higher publication year than the true year. Given the mean (which is actually quite decent), the main problem might be some heavy outliers in the model's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Predicted_y  Publication_year  Difference\n",
      "143  1482.561566              1647 -164.438434\n",
      "183  1531.163409              1679 -147.836591\n",
      "2    1517.937050              1663 -145.062950\n",
      "170  1763.628141              1895 -131.371859\n",
      "54   1775.478628              1897 -121.521372\n",
      "188  1779.429106              1893 -113.570894\n",
      "159  1783.201390              1890 -106.798610\n",
      "50   1784.179079              1889 -104.820921\n",
      "47   1801.314523              1898  -96.685477\n",
      "116  1820.343756              1913  -92.656244\n"
     ]
    }
   ],
   "source": [
    "print(diff_pred_true_val.nsmallest(10,'Difference'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "eli5 instance 119 and 142: The model predicts 2012 and 2014 (true: 1765 and 1895), probably because it overestimates the influence of the word \"dem\". In the instance of 2012, \"dem\" has a weight of +348, whereas for the one with 2014, it is weighted with +71. \n",
    "\n",
    "\"die\" seems also to be a word that misleads the classifier to think that a text is younger than it really is. For the text of 2012, \"die\" has a weight of +185, for the example that was predicted with 2014, the weight is +65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_pred_true_val.to_csv('/Volumes/Korpora/Reg4_Labels_val.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_pred_true_train.to_csv('/Volumes/Korpora/Reg4_Labels_train.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eli5.explain_prediction(reg_4['ridge_reg'],val_x[143],vec=reg_4['unigram_vectorizer'], feature_names=features_selected, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl = eli5.explain_prediction_df(reg_4['ridge_reg'],val_x[0],vec=reg_4['unigram_vectorizer'], feature_names=features_selected)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(expl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>&lt;BIAS&gt;</td>\n",
       "      <td>1769.724984</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>y</td>\n",
       "      <td>'welchem'</td>\n",
       "      <td>0.112434</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>y</td>\n",
       "      <td>'gleichen'</td>\n",
       "      <td>0.080908</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>y</td>\n",
       "      <td>'findet'</td>\n",
       "      <td>0.240282</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>y</td>\n",
       "      <td>'welches'</td>\n",
       "      <td>0.016883</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>y</td>\n",
       "      <td>'nen'</td>\n",
       "      <td>0.014924</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>y</td>\n",
       "      <td>'bleibt'</td>\n",
       "      <td>0.174982</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>y</td>\n",
       "      <td>'zeiten'</td>\n",
       "      <td>-0.310498</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>y</td>\n",
       "      <td>'liegen'</td>\n",
       "      <td>0.608372</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>y</td>\n",
       "      <td>'dahin'</td>\n",
       "      <td>0.083053</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target      feature       weight  value\n",
       "0        y       <BIAS>  1769.724984    1.0\n",
       "111      y    'welchem'     0.112434    1.0\n",
       "113      y   'gleichen'     0.080908    1.0\n",
       "100      y     'findet'     0.240282    2.0\n",
       "116      y    'welches'     0.016883    2.0\n",
       "117      y        'nen'     0.014924    2.0\n",
       "106      y     'bleibt'     0.174982    3.0\n",
       "127      y     'zeiten'    -0.310498    3.0\n",
       "83       y     'liegen'     0.608372    4.0\n",
       "112      y      'dahin'     0.083053    4.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expl.nsmallest(10,'value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>y</td>\n",
       "      <td>&lt;BIAS&gt;</td>\n",
       "      <td>1769.724984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>y</td>\n",
       "      <td>'keine'</td>\n",
       "      <td>0.282159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>y</td>\n",
       "      <td>'weiter'</td>\n",
       "      <td>0.260575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>y</td>\n",
       "      <td>'ja'</td>\n",
       "      <td>0.216977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>y</td>\n",
       "      <td>'that'</td>\n",
       "      <td>0.181377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>y</td>\n",
       "      <td>'gen'</td>\n",
       "      <td>-0.176596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>y</td>\n",
       "      <td>'bald'</td>\n",
       "      <td>-0.179685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>y</td>\n",
       "      <td>'ins'</td>\n",
       "      <td>-0.221891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>y</td>\n",
       "      <td>'weit'</td>\n",
       "      <td>-0.229857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>y</td>\n",
       "      <td>'kein'</td>\n",
       "      <td>-0.339552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>216 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    target    feature       weight\n",
       "0        y     <BIAS>  1769.724984\n",
       "1        y    'keine'     0.282159\n",
       "2        y   'weiter'     0.260575\n",
       "3        y       'ja'     0.216977\n",
       "4        y     'that'     0.181377\n",
       "..     ...        ...          ...\n",
       "211      y      'gen'    -0.176596\n",
       "212      y     'bald'    -0.179685\n",
       "213      y      'ins'    -0.221891\n",
       "214      y     'weit'    -0.229857\n",
       "215      y     'kein'    -0.339552\n",
       "\n",
       "[216 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.explain_weights_df(reg_4['ridge_reg'],vec=reg_4['unigram_vectorizer'], feature_names=features_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_details = collect_predictions(val_x, reg_4['ridge_reg'],reg_4['unigram_vectorizer'],features_selected, reg_4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46786"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_details = collect_predictions(train_x, reg_4['ridge_reg'],reg_4['unigram_vectorizer'],features_selected, reg_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_details.to_csv('/Volumes/Korpora/Exp2_Reg4_Train_results.csv',sep=';')\n",
    "val_details.to_csv('/Volumes/Korpora/Exp2_Reg4_Val_results.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <span>R/rpy2 DataFrame (6 x 218)</span>\n",
       "    <table>\n",
       "      <thead>\n",
       "        <tr>\n",
       "        \n",
       "          <th>instance</th>\n",
       "        \n",
       "          <th>'</th>\n",
       "        \n",
       "          <th>''</th>\n",
       "        \n",
       "          <th>...</th>\n",
       "        \n",
       "          <th>'</th>\n",
       "        \n",
       "          <th><BIAS></th>\n",
       "        \n",
       "          <th>YEAR</th>\n",
       "        \n",
       "        </tr>\n",
       "      </thead>\n",
       "      <tbody>\n",
       "      \n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        0\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        29084.580028\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        9.531435\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        15941.572583\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1769.724984\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1786.000000\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        1\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        478.880845\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        68.646378\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        262.479766\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1769.724984\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1750.000000\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        2\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        295.635624\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.286816\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        162.041080\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1769.724984\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1771.000000\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        3\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        434022.577617\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        527.425577\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        237892.464570\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1769.724984\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1794.000000\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        4\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        43578.903110\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        0.321552\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        23886.067681\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1769.724984\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1893.000000\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      \n",
       "      <tr>\n",
       "      \n",
       "      <td>\n",
       "        5\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        123661.592716\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        NA_real_\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        ...\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        67780.255178\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1769.724984\n",
       "      </td>\n",
       "      \n",
       "      <td>\n",
       "        1852.000000\n",
       "      </td>\n",
       "      \n",
       "      </tr>\n",
       "      \n",
       "      </tbody>\n",
       "    </table>\n",
       "    "
      ],
      "text/plain": [
       "R object with classes: ('data.frame',) mapped to:\n",
       "<DataFrame - Python:0x1f1fba4b0 / R:0x7f957b217600>\n",
       "[IntVector, FloatVector, FloatVector, FloatVector, ..., FloatVector, FloatVector, FloatVector, FloatVector]\n",
       "  instance: <class 'rpy2.robjects.vectors.IntVector'>\n",
       "  R object with classes: ('integer',) mapped to:\n",
       "<IntVector - Python:0x15b4025f0 / R:0x7f957fe4e8b8>\n",
       "[0, 1, 2, 3, 4, 5]\n",
       "  ': <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x15b402a00 / R:0x7f957e9c2ac8>\n",
       "[29084.580028, 478.880845, 295.635624, 434022.577617, 43578.903110, 123661.592716]\n",
       "  '': <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x157747af0 / R:0x7f957e9c25f8>\n",
       "[9.531435, 68.646378, 0.286816, 527.425577, 0.321552, NA_real_]\n",
       "  '.': <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x157747cd0 / R:0x7f957e9c24a8>\n",
       "[-4224.971867, -23516.296288, -9100.800304, -359981.927132, -5801.206401, -19843.862241]\n",
       "...\n",
       "  '3': <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x157747e60 / R:0x7f957eb2f568>\n",
       "[-70.571991, -106.295417, -2.332958, -2837.497092, -9.331834, -22.782797]\n",
       "  ':': <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x15a32ab40 / R:0x7f957eb2f418>\n",
       "[15941.572583, 262.479766, 162.041080, 237892.464570, 23886.067681, 67780.255178]\n",
       "   ';': <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x1f1467a50 / R:0x7f957eb2f108>\n",
       "[1769.724984, 1769.724984, 1769.724984, 1769.724984, 1769.724984, 1769.724984]\n",
       "  '?': <class 'rpy2.robjects.vectors.FloatVector'>\n",
       "  R object with classes: ('numeric',) mapped to:\n",
       "<FloatVector - Python:0x15b402410 / R:0x7f957eb2efb8>\n",
       "[1786.000000, 1750.000000, 1771.000000, 1794.000000, 1893.000000, 1852.000000]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ListVector' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-f201dca7b7ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_details_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_plot\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maes_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'YEAR'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mggplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeom_bar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'ListVector' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "train_plot = ggplot.ggplot(R_train_det)\n",
    "\n",
    "train_details_plot = train_plot + ggplot.aes_string(x='YEAR') + ggplot.geom_bar()\n",
    "    \n",
    "train_plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
