{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment 4: DTA, linear regression and subwords**\n",
    "\n",
    "*Background*: Experiment 2 shows that linear regression with 215 features does not overfit anymore, but the model does not fit the beginning and the end of the timerange. Quadratic polynomial regression would be a possibility, but quadratic polynomial regression performs worse on both training and validation set than linear regression. Polynomial regression with a degree of 5 cannot be computed due to the vast number of polynomial features created by the model.\n",
    "\n",
    "*Goal*: Determine if it is possible to predict the year in which a text was written using regression.\n",
    "\n",
    "*Strategies*:\n",
    "\n",
    "- Use a BPE-transformer to train on subwords (Sennrich2016)\n",
    "\n",
    "*Relevance*:\n",
    "\n",
    "- If this experiment works, it is possible to estimate years for corpora that have NA's in this variable.\n",
    "- Subwords might increase the amount of generalization, and minimize the vocabulary used at the same time.\n",
    "\n",
    "*Success criteria*:\n",
    "\n",
    "- Consistent findings over training-, test- and validation set\n",
    "- predicted year is not more than ten years away from the true year\n",
    "\n",
    "*Corpora*:\n",
    "\n",
    "- DTA\n",
    "\n",
    "*Baseline to beat (Exp. 2)*:\n",
    "- Train MSE = 2259.8\n",
    "- Val MSE = 3202.51\n",
    "\n",
    "*Result*: - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dianaenggist/opt/anaconda3/envs/R_python/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/dianaenggist/opt/anaconda3/envs/R_python/lib/python3.7/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_selection.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_selection. Anything that cannot be imported from sklearn.feature_selection is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest , f_regression\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import sklearn.utils\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from Selfwritten_modules.SubwordTransformer import SubwordTransformer\n",
    "\n",
    "import re\n",
    "\n",
    "import eli5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build tokenizer that just substitutes '[' and ']' with ','\n",
    "def tokenizer_word(doc):\n",
    "    doc = re.sub('[(\\[+)|(\\]+)]', '', doc)\n",
    "    doc = re.split(',', doc)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for assembling predictions in order to find out how features are weighted\n",
    "\n",
    "def collect_predictions(dataset, classifier,vectorizer, feature_names, pipeline):\n",
    "    predictions = eli5.explain_weights_df(classifier,vec=vectorizer, feature_names=feature_names)\n",
    "    \n",
    "    predictions = predictions.drop(['target'], axis=1)\n",
    "    \n",
    "    \n",
    "    predictions['YEAR'] = 0\n",
    "    \n",
    "    \n",
    "\n",
    "    for instance in range (0, len(dataset)):\n",
    "        pred = eli5.explain_prediction_df(classifier, dataset[instance], vec=vectorizer, feature_names=feature_names)\n",
    "        source_text = pd.DataFrame([[dataset[instance]]])\n",
    "        year_pred = pipeline.predict(source_text[0])\n",
    "        pred['weight_value'] = pred['weight'] * pred['value']\n",
    "        pred['instance'] = instance\n",
    "        \n",
    "        \n",
    "        pred = pred.drop(['target','weight','value'], axis=1)\n",
    "        \n",
    "    \n",
    "        pred['YEAR'] = np.round(year_pred[0])\n",
    "    \n",
    "        predictions = pd.concat([predictions, pred])\n",
    "    \n",
    "    \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full = pd.read_csv('/Volumes/Korpora/Train/DTA_train_tokenized.csv', sep=';')\n",
    "val_full = pd.read_csv('/Volumes/Korpora/Val/DTA_val_tokenized.csv', sep=';')\n",
    "#test_full = pd.read_csv('/Volumes/Korpora/Test/DTA_test_tokenized.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length train set:  899\n",
      "Length validation set:  225\n"
     ]
    }
   ],
   "source": [
    "print('Length train set: ',len(train_full))\n",
    "print('Length validation set: ', len(val_full))\n",
    "#print('Length test set: ', len(test_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_full['Text']\n",
    "train_y = train_full['Publication_year']\n",
    "\n",
    "val_x = val_full['Text']\n",
    "val_y = val_full['Publication_year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline takes a lot of time to run through. To determine were the problem is, I'm going to go through the subword transformer stepwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SubwordTransformer(n_best=5, number_of_merges=10,\n",
       "                   tokenizer=<function tokenizer_word at 0x11e3dc7a0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subwords = SubwordTransformer(tokenizer=tokenizer_word)\n",
    "\n",
    "subwords.fit(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subwords.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the subword algorithm seems to extract only 10 subwords. This is the number of merges the algorithm performs per default.\n",
    "It also seems to use about one minute per merge. Maybe it would be useful to extract the k_best pairs each time instead of only the best pair.\n",
    "\n",
    "The transformation process took the algorithm really long, but I fixed it, now the speed is better.\n",
    "\n",
    "Update: Parallelizing the extraction of the subwords really helped to gather more features in less time. So I would suggest to rather increase the features extracted at the same time step than the number of merges done, at least when time plays a role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_transformed = subwords.transform(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_1 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=5, n_best = 50)),\n",
    "                ('ridge_reg', linear_model.Ridge())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=50, number_of_merges=5,\n",
       "                                    tokenizer=<function tokenizer_word at 0x11e3dc7a0>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_1.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1856.134944837302"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_1.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5607.611798707225"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_1.predict(val_x)\n",
    "\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_2 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=10, n_best = 25)),\n",
    "                ('ridge_reg', linear_model.Ridge())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=25, number_of_merges=10,\n",
       "                                    tokenizer=<function tokenizer_word at 0x11e3dc7a0>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_2.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1705.4578667527232"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_2.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5158.148065706169"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_2.predict(val_x)\n",
    "\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_3 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=1, n_best = 250)),\n",
    "                ('ridge_reg', linear_model.Ridge())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=250, number_of_merges=1,\n",
       "                                    tokenizer=<function tokenizer_word at 0x11e3dc7a0>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_3.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1401.2375448462706"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_3.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9079.520901710413"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_3.predict(val_x)\n",
    "\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subwords do not beat the baseline yet, but it is very close to it. It seems that the number of merges does increase the performance slightly. We also have more features than the linear regression on which the baseline was trained. So let's play around with the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_4 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=10, n_best = 10)),\n",
    "                ('ridge_reg', linear_model.Ridge())\n",
    "                        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=10, number_of_merges=10,\n",
       "                                    tokenizer=<function tokenizer_word at 0x11e3dc7a0>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_4.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.033363106020776016"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_4.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1116084.7998909994"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_4.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "100 features with a lot of merges and few words loaded per merge leads to heavily overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_5 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=5, n_best = 20)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=20, number_of_merges=5,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_5.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2715.818723121653"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_5.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3321.3020605132606"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_5.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_6 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=2, n_best = 50)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=50, number_of_merges=2,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_6.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2575.599149907795"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_6.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3447.358455480043"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_6.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_7 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=1, n_best = 100)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=100, number_of_merges=1,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_7.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500.7412722986505"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_7.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3745.6498662387094"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_7.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_8 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=2, n_best = 60)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=60, number_of_merges=2,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_8.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2465.011096075109"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_8.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3602.910503824884"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_8.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_9 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=2, n_best = 80)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=80, number_of_merges=2,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_9.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2222.48922717676"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_9.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3667.109164393909"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_9.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_10 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=2, n_best = 70)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=70, number_of_merges=2,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_10.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2192.9760224052943"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_10.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4156.00168293966"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_10.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_11 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=3, n_best = 50)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=50, number_of_merges=3,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_11.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2154.155532780347"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_11.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4410.141749003236"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_11.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_12 = Pipeline([('subwords', SubwordTransformer(tokenizer=tokenizer_word, number_of_merges=3, n_best = 30)),\n",
    "                ('ridge_reg', linear_model.Ridge())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('subwords',\n",
       "                 SubwordTransformer(n_best=30, number_of_merges=3,\n",
       "                                    tokenizer=<function tokenizer_word at 0x1250d3b90>)),\n",
       "                ('ridge_reg',\n",
       "                 Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
       "                       max_iter=None, normalize=False, random_state=None,\n",
       "                       solver='auto', tol=0.001))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_12.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2148.1071957613735"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_train = reg_12.predict(train_x)\n",
    "mean_squared_error(train_y, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4429.4427212795745"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_val = reg_12.predict(val_x)\n",
    "mean_squared_error(val_y, y_pred_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
